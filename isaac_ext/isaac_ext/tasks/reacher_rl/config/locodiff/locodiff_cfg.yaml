defaults:
  - model: transformer
  - _self_

logger: wandb
wandb_project: locodiff_isaac
num_iters: 5e5
seed: 42
resume: false
episode_length: 5

# training
log_interval: 100
eval_interval: 1e3
sim_interval: 5e3
device: cuda
ema_decay: 0.999
use_ema: True

#dims
obs_dim: null
act_dim: null
T: 4
T_cond: 8
T_action: 1
num_envs: 64

# diffusion
sampling_steps: 10
cond_mask_prob: 0

policy:
  obs_dim: ${obs_dim}
  act_dim: ${act_dim}
  T: ${T}
  T_cond: ${T_cond}
  num_envs: ${num_envs}
  sampling_steps: ${sampling_steps}
  sampler_type: ddim
  sigma_data: 0.5
  sigma_min: 0.001
  sigma_max: 80
  cond_lambda: 1
  cond_mask_prob: ${cond_mask_prob}
  lr: 1e-4
  betas: [0.9, 0.999]
  num_iters: ${num_iters}
  inpaint_obs: true
  inpaint_final_obs: false
  device: ${device}

dataset:
  data_directory: logs/reacher_rl_record/hdf_dataset.hdf5
  train_fraction: 0.95
  device: ${device}
  T_cond: ${T_cond}
  T: ${T}
  train_batch_size: 1024
  test_batch_size: 1024
  num_workers: 4
  scaling: linear
  evaluating: false

hydra:
  run:
    dir: logs/locodiff/${now:%b-%d}/${now:%H-%M-%S}
